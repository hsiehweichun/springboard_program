{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/weichun/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.feature_selection import RFE, RFECV, f_regression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.cross_validation import KFold, train_test_split , cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [\"employee_index\",\"country_residence\",\"sex\",\"age\",\"first_join_date\",\"new_customer_index\",\"seniority\",\"primary\",\"customer_type\",\"customer_relation\",\"residence_idx\",\"foreigner_idx\",\"channel\",\"deceased\",\"address\",\"province_code\",\"province_name\",\"activity_idx\",\"gross_income\",\"segment\"]\n",
    "#target_cols=[\"saving_account\",\"guarantees\",\"current_account\",\"derivada_account\",\"payroll_account\",\"junior_account\",\"mas_particular_account\",\"particular_account\",\"particular_plus_account\",\"short-term_deposits\",\"medium-term_deposits\",\"long-term_deposits\",\"e-account\",\"funds\",\"mortgage\",\"pensions\",\"loans\",\"taxes\",\"credit_card\",\"securities\",\"home_account\",\"payroll\",\"pensions_1\",\"direct_debit\"]\n",
    "#target_cols = target_cols[2:]\n",
    "target_cols = [\"current_account\"]\n",
    "all_cols = feature_cols+target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTarget(row):\n",
    "    tlist = []\n",
    "    for col in target_cols:\n",
    "            if row[col].strip() in ['', 'NA']:\n",
    "                    target = 0\n",
    "            else:\n",
    "                    target = int(float(row[col]))\n",
    "            tlist.append(target)\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processData(in_file_name):\n",
    "    x_vars_list = []\n",
    "    #y_vars_list = []\n",
    "    for row in csv.DictReader(in_file_name, fieldnames = ( \"date\",\"id\",\"employee_index\",\"country_residence\",\"sex\",\n",
    "                                                          \"age\",\"first_join_date\",\"new_customer_index\",\"seniority\",\n",
    "                                                          \"primary\",\"last_date_primary\",\"customer_type\",\"customer_relation\",\n",
    "                                                          \"residence_idx\",\"foreigner_idx\",\"spouse_idx\",\"channel\",\"deceased\",\n",
    "                                                          \"address\",\"province_code\",\"province_name\",\"activity_idx\",\n",
    "                                                          \"gross_income\",\"segment\",\"saving_account\",\"guarantees\",\n",
    "                                                          \"current_account\",\"derivada_account\",\"payroll_account\",\n",
    "                                                          \"junior_account\",\"mas_particular_account\",\"particular_account\",\n",
    "                                                          \"particular_plus_account\",\"short-term_deposits\",\"medium-term_deposits\",\n",
    "                                                          \"long-term_deposits\",\"e-account\",\"funds\",\"mortgage\",\"pensions\",\"loans\",\n",
    "                                                          \"taxes\",\"credit_card\",\"securities\",\"home_account\",\"payroll\",\n",
    "                                                          \"pensions_1\",\"direct_debit\" )):\n",
    "        x_vars = []\n",
    "        for col in feature_cols:\n",
    "            val = row[col].strip()\n",
    "            x_vars.append(val)\n",
    "            \n",
    "        if row['date'] in [ '2016-05-28']:\n",
    "            target_list = getTarget(row)\n",
    "            x_vars_list.append(x_vars + target_list)\n",
    "            \n",
    "#assign a number for the test data\n",
    "        elif row['date'] in ['2016-06-28']: \n",
    "             target_list = [0]\n",
    "             x_vars_list.append(x_vars + target_list)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return x_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe:\n",
      "21\n",
      "Number of records in the dataframe:\n",
      "931453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = datetime.datetime.now()\n",
    "data_path = \"../input/\"\n",
    "train_file =  open(data_path + \"train_ver2.csv\")\n",
    "#train_file =  open(data_path + \"train_20percent.csv\")\n",
    "x_vars_list = processData(train_file)\n",
    "\n",
    "\n",
    "df_org = pd.DataFrame.from_records(x_vars_list, columns=all_cols)\n",
    "df = df_org\n",
    "print(\"Number of columns in the dataframe:\")\n",
    "print(len(x_vars_list[1]))  \n",
    "print(\"Number of records in the dataframe:\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_org = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['customer_type']=df['customer_type'].replace('1.0','1')\n",
    "df['customer_type']=df['customer_type'].replace('2.0','2')\n",
    "df['customer_type']=df['customer_type'].replace('3.0','3')\n",
    "df['customer_type']=df['customer_type'].replace('4.0','4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 702435 entries, 0 to 931451\n",
      "Data columns (total 21 columns):\n",
      "employee_index        702435 non-null object\n",
      "country_residence     702435 non-null object\n",
      "sex                   702435 non-null object\n",
      "age                   702435 non-null int64\n",
      "first_join_date       702435 non-null object\n",
      "new_customer_index    702435 non-null object\n",
      "seniority             702435 non-null int64\n",
      "primary               702435 non-null object\n",
      "customer_type         702435 non-null object\n",
      "customer_relation     702435 non-null object\n",
      "residence_idx         702435 non-null object\n",
      "foreigner_idx         702435 non-null object\n",
      "channel               702435 non-null object\n",
      "deceased              702435 non-null object\n",
      "address               702435 non-null object\n",
      "province_code         702435 non-null object\n",
      "province_name         702435 non-null object\n",
      "activity_idx          702435 non-null object\n",
      "gross_income          702435 non-null float64\n",
      "segment               702435 non-null object\n",
      "current_account       702435 non-null int64\n",
      "dtypes: float64(1), int64(3), object(17)\n",
      "memory usage: 117.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Age and seniority may have non-numeric values. Use errors='coerce' to force them to be NaN so they can be removed.\n",
    "\n",
    "df['age']   = pd.to_numeric(df['age'], errors='coerce')\n",
    "df['seniority']   = pd.to_numeric(df['seniority'], errors='coerce')\n",
    "df['gross_income']   = pd.to_numeric(df['gross_income'], errors='coerce')\n",
    "\n",
    "##df = df[df['seniority']>0]\n",
    "##df.dropna(axis=0)\n",
    "#df.dropna()\n",
    "\n",
    "#select the rows that do not have NaN\n",
    "condition=~pd.isnull(df).any(axis=1)\n",
    "df=df[condition]\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_numeric_data(df):\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    feature_cols = df.columns \n",
    "    for ind, feature_col in enumerate(feature_cols):\n",
    "        if df[feature_col].dtype == 'object':\n",
    "            le.fit(df[feature_col])\n",
    "            df[feature_col]=le.transform(df[feature_col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/weichun/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = prep_numeric_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe:\n",
      "21\n",
      "Number of records in the dataframe:\n",
      "702435\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns in the dataframe:\")\n",
    "print(len(x_vars_list[1]))  \n",
    "print(\"Number of records in the dataframe:\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X = df.drop(['address','current_account'],axis=1).values\n",
    "y = df['current_account'].values\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df = df.drop(['address','current_account'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split the data in test and train splits - why is this important ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X, y = dataset.iloc[:, :13].values, dataset.iloc[:, 13].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 470631\n",
      "Test data 231804\n"
     ]
    }
   ],
   "source": [
    "print ('Train data', len(X_train))\n",
    "print ('Test data', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Base Model\n",
    "\n",
    "Lets establish a baseline by building a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC-RIC : 0.621722217682\n",
      "Test AUC-ROC : 0.621773825356\n",
      "Accuracy Train : 0.602406131343\n",
      "Accuracy Test : 0.602427050439\n"
     ]
    }
   ],
   "source": [
    "print ('Training AUC-RIC :', roc_auc_score(y_train, logit.predict_proba(X_train)[:,1]))\n",
    "print ('Test AUC-ROC :', roc_auc_score(y_test, logit.predict_proba(X_test)[:,1]))\n",
    "print ('Accuracy Train :', accuracy_score(y_train, logit.predict(X_train)))\n",
    "print ('Accuracy Test :',  accuracy_score(y_test, logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, logit.predict_proba(X_test)[:,1], pos_label=1)\n",
    "roc = roc_auc_score(y_test, logit.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3ef55e0a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAEWCAYAAAB/mA49AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJXUREZE0oaQuIiKSJv4fP2kIwrcfwNMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3efd9fd358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve\n",
    "plt,figure(figsize=(8,4))\n",
    "plt.plot(fpr, tpr, 'r--', label=' ROC (area = %0.2f)' % roc, lw=2)\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('Receiver Operator Characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.13      0.20     92493\n",
      "          1       0.61      0.92      0.74    139311\n",
      "\n",
      "avg / total       0.57      0.60      0.52    231804\n",
      "\n",
      "[[ 11624  80869]\n",
      " [ 11290 128021]]\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, logit.predict(X_test)))\n",
    "print (confusion_matrix(y_test, logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nonlinearity - Interactions ans cross terms \n",
    "\n",
    "Very often we know that combining features we already know of to form new features help improve our model. In practice, this is done by creating feature iteractions / crossing different features to see which combinations add the most value to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Building base model\n",
    "logit_interactions = LogisticRegression()\n",
    "crossvalidation = KFold(n=X.shape[0], n_folds=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding interaction to model\n",
    "df = pd.DataFrame(X,columns=boston.feature_names)\n",
    "baseline = np.mean(cross_val_score(logit_interactions, df, y, scoring='accuracy', cv=crossvalidation, n_jobs=1))\n",
    "interactions = list()\n",
    "for feature_A in boston.feature_names:\n",
    "    for feature_B in boston.feature_names:\n",
    "        if feature_A > feature_B:\n",
    "            df['interaction'] = df[feature_A] * df[feature_B]\n",
    "            score = np.mean(cross_val_score(logit_interactions, df, y, scoring='accuracy',cv=crossvalidation, n_jobs=1))\n",
    "            if score > baseline:\n",
    "                interactions.append((feature_A, feature_B, round(score,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.913\n",
      "Top 10 interactions: [('RAD', 'DIS', 0.927), ('RM', 'DIS', 0.925), ('DIS', 'CRIM', 0.923), ('RAD', 'AGE', 0.923), ('TAX', 'DIS', 0.923), ('ZN', 'RM', 0.921), ('INDUS', 'DIS', 0.921), ('RM', 'INDUS', 0.921), ('RM', 'AGE', 0.921), ('RM', 'RAD', 0.919)]\n"
     ]
    }
   ],
   "source": [
    "print 'Baseline Accuracy: %.3f' % baseline\n",
    "print 'Top 10 interactions: %s' % sorted(interactions, key=lambda(x):x[2],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Features\n",
    "\n",
    "Here we strive the select the best subset of features that improves the performance of our models. There are many ways to do this but we will focus on just a few techniques.\n",
    "\n",
    "- Univariate selections of features : You individually model each predictor with the response and select the best features based on some statistical score or p-value. Some examples include f_regression which tests the effect of a single regressor sequentially for many regressors\n",
    "\n",
    "- Forward / Backward feature selection : This is a class of greedy feature selection algorithms. With Backward feature selection, we start with all the features in the model and then eliminate one feature at a time until we get to point where all the remaining features are either significant or meet a certain p-value threshould that we have defined whereas with Forward feature selection. we basically start modeling the response with one feature and if that feature meets our preset threshlod we keep in the model and add the next feature. One of the issues with forward selection is that you loose the ability ot look ahead.\n",
    "\n",
    "- Chi2 : chi2 measuree the dependence between stochastic variables, so the chi2 removes featurs that are most likely to be independent of class and therefore not useful for classification\n",
    "\n",
    "- Recursive Feature Eliminaation : Here, we train on the initial set of features. Then features are assigned weights and subsequently prunned from the model. This process continues until we get the desired number of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Eliminaation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  8,  9, 13, 18, 14, 15, 19,  4,  3,  5, 10, 16, 11, 12,  1,\n",
       "       17,  2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ranking among all features by selecting only one\n",
    "rfe = RFE(LogisticRegression(), n_features_to_select=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['employee_index', 'country_residence', 'sex', 'age', 'first_join_date',\n",
       "       'new_customer_index', 'seniority', 'primary', 'customer_type',\n",
       "       'customer_relation', 'residence_idx', 'foreigner_idx', 'channel',\n",
       "       'deceased', 'province_code', 'province_name', 'activity_idx',\n",
       "       'gross_income', 'segment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipe_rfe_poly = Pipeline([('scale_standard', StandardScaler()),\n",
    "#                      ('poly_features', PolynomialFeatures()),\n",
    "#                      ('rfe_logit', RFECV(LogisticRegression(), cv=10))])\n",
    "# pipe_rfe_poly.fit(X_train, y_train)\n",
    "# pipe_rfe_poly.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False False False False False False  True  True  True\n",
      " False False False False  True False  True]\n",
      "Index(['employee_index', 'country_residence', 'sex', 'customer_relation',\n",
      "       'residence_idx', 'foreigner_idx', 'activity_idx', 'segment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## using RFECV\n",
    "rfe = RFECV(LogisticRegression(), cv=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "print(rfe.support_)\n",
    "#print(boston.feature_names[rfe.support_])\n",
    "print(X_train.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward / Backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   41.8s finished\n",
      "\n",
      "[2017-09-06 14:32:04] Features: 1/7 -- score: 0.603066946501[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   58.4s finished\n",
      "\n",
      "[2017-09-06 14:33:03] Features: 2/7 -- score: 0.603861632655[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.2min finished\n",
      "\n",
      "[2017-09-06 14:34:17] Features: 3/7 -- score: 0.684672288824[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.4min finished\n",
      "\n",
      "[2017-09-06 14:35:41] Features: 4/7 -- score: 0.710539693066[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.6min finished\n",
      "\n",
      "[2017-09-06 14:37:20] Features: 5/7 -- score: 0.71055244198[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  1.7min finished\n",
      "\n",
      "[2017-09-06 14:39:04] Features: 6/7 -- score: 0.710560941226[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  1.9min finished\n",
      "\n",
      "[2017-09-06 14:40:58] Features: 7/7 -- score: 0.710601312485"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "             floating=False, forward=True, k_features=7, n_jobs=1,\n",
       "             pre_dispatch='2*n_jobs', scoring=None, skip_if_stuck=True,\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward Feature selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "sfs = SequentialFeatureSelector(LogisticRegression(), forward=True, floating = False, k_features=7, verbose = 2)\n",
    "sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3, 7, 10, 15, 16, 18)\n",
      "Index(['employee_index', 'age', 'primary', 'residence_idx', 'province_name',\n",
      "       'activity_idx', 'segment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sfs.k_feature_idx_)\n",
    "#print(boston.feature_names[np.array(sfs.k_feature_idx_)])\n",
    "print(X_df.columns[np.array(sfs.k_feature_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 19.4min finished\n",
      "\n",
      "[2017-09-06 15:16:01] Features: 18/7 -- score: 0.623362915637[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   53.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 15.8min finished\n",
      "\n",
      "[2017-09-06 15:31:51] Features: 17/7 -- score: 0.710518444681[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 10.8min finished\n",
      "\n",
      "[2017-09-06 15:42:40] Features: 16/7 -- score: 0.710686306386[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 12.3min finished\n",
      "\n",
      "[2017-09-06 15:55:00] Features: 15/7 -- score: 0.711036894018[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   54.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 10.8min finished\n",
      "\n",
      "[2017-09-06 16:05:47] Features: 14/7 -- score: 0.712199164128[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   40.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  9.6min finished\n",
      "\n",
      "[2017-09-06 16:15:22] Features: 13/7 -- score: 0.71058006437[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  3.2min finished\n",
      "\n",
      "[2017-09-06 16:18:37] Features: 12/7 -- score: 0.710582189114[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  2.7min finished\n",
      "\n",
      "[2017-09-06 16:21:20] Features: 11/7 -- score: 0.710584313903[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  1.7min finished\n",
      "\n",
      "[2017-09-06 16:23:00] Features: 10/7 -- score: 0.710584313903[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "\n",
      "[2017-09-06 16:24:28] Features: 9/7 -- score: 0.710584313903[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min finished\n",
      "\n",
      "[2017-09-06 16:25:45] Features: 8/7 -- score: 0.710584313903[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.2min finished\n",
      "\n",
      "[2017-09-06 16:26:56] Features: 7/7 -- score: 0.710577939536"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "             floating=False, forward=False, k_features=7, n_jobs=1,\n",
       "             pre_dispatch='2*n_jobs', scoring=None, skip_if_stuck=True,\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward Feature selection\n",
    "sbs = SequentialFeatureSelector(LogisticRegression(), forward=False, floating = False, k_features=7, verbose = 2)\n",
    "sbs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2, 7, 12, 14, 16, 18)\n",
      "Index(['employee_index', 'sex', 'primary', 'channel', 'province_code',\n",
      "       'activity_idx', 'segment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sbs.k_feature_idx_)\n",
    "print(X_df.columns[np.array(sbs.k_feature_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603067</td>\n",
       "      <td>7.78843e-05</td>\n",
       "      <td>[0.603142562708, 0.60304694721, 0.602961955656...</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>6.05966e-05</td>\n",
       "      <td>3.02983e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.603862</td>\n",
       "      <td>0.00145923</td>\n",
       "      <td>[0.604459931794, 0.602016424618, 0.60308944298...</td>\n",
       "      <td>(3, 7)</td>\n",
       "      <td>0.00113533</td>\n",
       "      <td>0.000567665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.00222448</td>\n",
       "      <td>[0.68597745599, 0.681441031797, 0.684617591127...</td>\n",
       "      <td>(16, 3, 7)</td>\n",
       "      <td>0.00173072</td>\n",
       "      <td>0.000865361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.71054</td>\n",
       "      <td>0.0028924</td>\n",
       "      <td>[0.711273067239, 0.706386052886, 0.71081623763...</td>\n",
       "      <td>(16, 18, 3, 7)</td>\n",
       "      <td>0.00225038</td>\n",
       "      <td>0.00112519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710552</td>\n",
       "      <td>0.00289051</td>\n",
       "      <td>[0.711283691183, 0.70639667683, 0.710816237636...</td>\n",
       "      <td>(3, 7, 10, 16, 18)</td>\n",
       "      <td>0.00224891</td>\n",
       "      <td>0.00112446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.710561</td>\n",
       "      <td>0.0029031</td>\n",
       "      <td>[0.711283691183, 0.70639667683, 0.710837485525...</td>\n",
       "      <td>(0, 3, 7, 10, 16, 18)</td>\n",
       "      <td>0.00225871</td>\n",
       "      <td>0.00112936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.710601</td>\n",
       "      <td>0.00289929</td>\n",
       "      <td>[0.711368682737, 0.706417924719, 0.71086935735...</td>\n",
       "      <td>(0, 3, 7, 10, 15, 16, 18)</td>\n",
       "      <td>0.00225575</td>\n",
       "      <td>0.00112787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  avg_score     ci_bound                                          cv_scores  \\\n",
       "1  0.603067  7.78843e-05  [0.603142562708, 0.60304694721, 0.602961955656...   \n",
       "2  0.603862   0.00145923  [0.604459931794, 0.602016424618, 0.60308944298...   \n",
       "3  0.684672   0.00222448  [0.68597745599, 0.681441031797, 0.684617591127...   \n",
       "4   0.71054    0.0028924  [0.711273067239, 0.706386052886, 0.71081623763...   \n",
       "5  0.710552   0.00289051  [0.711283691183, 0.70639667683, 0.710816237636...   \n",
       "6  0.710561    0.0029031  [0.711283691183, 0.70639667683, 0.710837485525...   \n",
       "7  0.710601   0.00289929  [0.711368682737, 0.706417924719, 0.71086935735...   \n",
       "\n",
       "                 feature_idx      std_dev      std_err  \n",
       "1                       (7,)  6.05966e-05  3.02983e-05  \n",
       "2                     (3, 7)   0.00113533  0.000567665  \n",
       "3                 (16, 3, 7)   0.00173072  0.000865361  \n",
       "4             (16, 18, 3, 7)   0.00225038   0.00112519  \n",
       "5         (3, 7, 10, 16, 18)   0.00224891   0.00112446  \n",
       "6      (0, 3, 7, 10, 16, 18)   0.00225871   0.00112936  \n",
       "7  (0, 3, 7, 10, 15, 16, 18)   0.00225575   0.00112787  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sfs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.710578</td>\n",
       "      <td>0.00290507</td>\n",
       "      <td>[0.711368682737, 0.706386052886, 0.71084810946...</td>\n",
       "      <td>(0, 2, 7, 12, 14, 16, 18)</td>\n",
       "      <td>0.00226024</td>\n",
       "      <td>0.00113012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.710584</td>\n",
       "      <td>0.00289527</td>\n",
       "      <td>[0.711368682737, 0.706407300774, 0.71085873341...</td>\n",
       "      <td>(0, 2, 7, 11, 12, 14, 16, 18)</td>\n",
       "      <td>0.00225262</td>\n",
       "      <td>0.00112631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.710584</td>\n",
       "      <td>0.00289527</td>\n",
       "      <td>[0.711368682737, 0.706407300774, 0.71085873341...</td>\n",
       "      <td>(0, 2, 5, 7, 11, 12, 14, 16, 18)</td>\n",
       "      <td>0.00225262</td>\n",
       "      <td>0.00112631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.710584</td>\n",
       "      <td>0.00289527</td>\n",
       "      <td>[0.711368682737, 0.706407300774, 0.71085873341...</td>\n",
       "      <td>(0, 2, 5, 7, 8, 11, 12, 14, 16, 18)</td>\n",
       "      <td>0.00225262</td>\n",
       "      <td>0.00112631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.710584</td>\n",
       "      <td>0.00289527</td>\n",
       "      <td>[0.711368682737, 0.706407300774, 0.71085873341...</td>\n",
       "      <td>(0, 2, 5, 7, 8, 11, 12, 13, 14, 16, 18)</td>\n",
       "      <td>0.00225262</td>\n",
       "      <td>0.00112631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.710582</td>\n",
       "      <td>0.00289697</td>\n",
       "      <td>[0.711358058793, 0.706407300774, 0.71085873341...</td>\n",
       "      <td>(0, 2, 5, 6, 7, 8, 11, 12, 13, 14, 16, 18)</td>\n",
       "      <td>0.00225394</td>\n",
       "      <td>0.00112697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.71058</td>\n",
       "      <td>0.00290828</td>\n",
       "      <td>[0.711368682737, 0.706386052886, 0.71084810946...</td>\n",
       "      <td>(0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 18)</td>\n",
       "      <td>0.00226274</td>\n",
       "      <td>0.00113137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.712199</td>\n",
       "      <td>0.00446799</td>\n",
       "      <td>[0.716914381633, 0.706417924719, 0.71085873341...</td>\n",
       "      <td>(0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>0.00347625</td>\n",
       "      <td>0.00173812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.711037</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>[0.713684702583, 0.706375428942, 0.71081623763...</td>\n",
       "      <td>(0, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>0.00260174</td>\n",
       "      <td>0.00130087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.710686</td>\n",
       "      <td>0.00310907</td>\n",
       "      <td>[0.711347434849, 0.706386052886, 0.71079498974...</td>\n",
       "      <td>(0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.00241896</td>\n",
       "      <td>0.00120948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.710518</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>[0.711358058793, 0.706332933165, 0.71079498974...</td>\n",
       "      <td>(0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>0.00226252</td>\n",
       "      <td>0.00113126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.623363</td>\n",
       "      <td>0.0559503</td>\n",
       "      <td>[0.602154535893, 0.601336492186, 0.71042315169...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0435312</td>\n",
       "      <td>0.0217656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.601996</td>\n",
       "      <td>0.00161144</td>\n",
       "      <td>[0.60149585135, 0.601485227406, 0.604321820519...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.00125375</td>\n",
       "      <td>0.000626877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_score    ci_bound                                          cv_scores  \\\n",
       "7   0.710578  0.00290507  [0.711368682737, 0.706386052886, 0.71084810946...   \n",
       "8   0.710584  0.00289527  [0.711368682737, 0.706407300774, 0.71085873341...   \n",
       "9   0.710584  0.00289527  [0.711368682737, 0.706407300774, 0.71085873341...   \n",
       "10  0.710584  0.00289527  [0.711368682737, 0.706407300774, 0.71085873341...   \n",
       "11  0.710584  0.00289527  [0.711368682737, 0.706407300774, 0.71085873341...   \n",
       "12  0.710582  0.00289697  [0.711358058793, 0.706407300774, 0.71085873341...   \n",
       "13   0.71058  0.00290828  [0.711368682737, 0.706386052886, 0.71084810946...   \n",
       "14  0.712199  0.00446799  [0.716914381633, 0.706417924719, 0.71085873341...   \n",
       "15  0.711037    0.003344  [0.713684702583, 0.706375428942, 0.71081623763...   \n",
       "16  0.710686  0.00310907  [0.711347434849, 0.706386052886, 0.71079498974...   \n",
       "17  0.710518    0.002908  [0.711358058793, 0.706332933165, 0.71079498974...   \n",
       "18  0.623363   0.0559503  [0.602154535893, 0.601336492186, 0.71042315169...   \n",
       "19  0.601996  0.00161144  [0.60149585135, 0.601485227406, 0.604321820519...   \n",
       "\n",
       "                                          feature_idx     std_dev      std_err  \n",
       "7                           (0, 2, 7, 12, 14, 16, 18)  0.00226024   0.00113012  \n",
       "8                       (0, 2, 7, 11, 12, 14, 16, 18)  0.00225262   0.00112631  \n",
       "9                    (0, 2, 5, 7, 11, 12, 14, 16, 18)  0.00225262   0.00112631  \n",
       "10                (0, 2, 5, 7, 8, 11, 12, 14, 16, 18)  0.00225262   0.00112631  \n",
       "11            (0, 2, 5, 7, 8, 11, 12, 13, 14, 16, 18)  0.00225262   0.00112631  \n",
       "12         (0, 2, 5, 6, 7, 8, 11, 12, 13, 14, 16, 18)  0.00225394   0.00112697  \n",
       "13     (0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 18)  0.00226274   0.00113137  \n",
       "14  (0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16,...  0.00347625   0.00173812  \n",
       "15  (0, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, ...  0.00260174   0.00130087  \n",
       "16  (0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  0.00241896   0.00120948  \n",
       "17  (0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  0.00226252   0.00113126  \n",
       "18  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   0.0435312    0.0217656  \n",
       "19  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  0.00125375  0.000626877  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sbs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating and Comparing Models\n",
    "- Confusion matriz : is basically a table that summarizes the performance of classification tasks across TP, TN, FP and FN. It also allows us to calculate several other metrics useful for classification problems\n",
    "- Area under the ROC curve : this is a plot of TPR (sensitivity) vs FPR (1 - specificity) for every possible classification threshold. It is a single graph / number summary for classifier performance. . It is also useful to understand the tradeoffs in classifier performance\n",
    "- Accuracy : this measures how ofter the classifier makes the correct prediction. It's easy to calculate but it doesn't tell us anything about the dependent values or the type of errors your classifier is making \n",
    "- Precision and Recall : Precision tell how often the prediction is correct when our classifier predicts a positive value whereas Recall tells us how often the prediction is correct when the actual value is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$Recall = \\frac{TP}{FN + TP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Precision = \\frac{TP}{FP + TP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Overfitting / Underfitting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Topics / Model Tyoes\n",
    "- Regularization : assign an appropriate penalty for model complexity (L1 , L2)\n",
    "- SVM : is large margin classifier. It provides a binary classification mechanism based on finding a hyperplane between a set of samples with +ve and -ve outputs. It assumes the data is linearly separable.\n",
    "- Ensemble Trees : Based on a tree of decision nodes, the learning approach is to recursively divide the training data into buckets of homogeneous members through the most discriminative dividing criteria possible. The measurement of homogeneity is based on the output label; when it is a numeric value, the measurement will be the variance of the bucket; when it is a category, the measurement will be the entropy, or gini index, of the bucket.\n",
    "- Neural Networks : A Neural Network emulates the structure of a human brain as a network of neurons that are interconnected to each other. Each neuron is technically equivalent to a logistic regression unit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
